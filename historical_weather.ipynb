{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests as req\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "\n",
    "import asyncio\n",
    "import aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenWeather API Key\n",
    "API_KEY = 'c5d22ed423af74ba40fc97b49c023304'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TRT data\n",
    "data_frame = pd.read_csv('dimTRTstore.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_start = int(datetime(2022,11,1,1,0).timestamp())\n",
    "month_end = int(datetime(2022,11,27,0,59,59).timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {}\n",
    "options[\"weather_url\"] = \"https://history.openweathermap.org/data/2.5/history/city\"\n",
    "options[\"type\"] = \"hour\"\n",
    "options[\"start\"] = str(month_start)\n",
    "options[\"end\"] = str(month_end)\n",
    "options[\"units\"] = \"metric\"\n",
    "options[\"api_key\"] = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_rounder(t):\n",
    "    # Rounds down to the nearest hour\n",
    "    return (t.replace(second=0, microsecond=0, minute=0, hour=t.hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds request url to access historical weather data from OpenWeather\n",
    "# Params: \n",
    "# lat: latitude of desired location\n",
    "# lon: longitude of desired location\n",
    "# return: request url for weather\n",
    "\n",
    "def request_weather_url(lat,lon):\n",
    "\n",
    "    REQUEST_URL = options[\"weather_url\"] + \"?lat=\" \\\n",
    "    + str(lat) \\\n",
    "    + \"&lon=\" + str(lon) \\\n",
    "    + \"&type=\" + options[\"type\"] \\\n",
    "    + \"&start=\" + options[\"start\"] \\\n",
    "    + \"&units=\" + options[\"units\"] \\\n",
    "    + \"&appid=\" + options[\"api_key\"]\n",
    "\n",
    "    return REQUEST_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER_URL_LIST = []\n",
    "for lat,lon in zip(data_frame[\"Latitude\"], data_frame[\"Longitude\"]):\n",
    "    WEATHER_URL_LIST.append(request_weather_url(lat,lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        json_response = await response.json(content_type='application/json')\n",
    "        json_response.update({'url': url})\n",
    "        await asyncio.sleep(1)\n",
    "        return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main_weather(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch(session, url) for url in WEATHER_URL_LIST]\n",
    "        return await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await main_weather(WEATHER_URL_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.json_normalize(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1[df1['list'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet('testing.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.json_normalize(data.to_dict(orient='records'), record_path=['list','weather'], record_prefix='weather.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.json_normalize(data.to_dict(orient='records'), record_path=['list'], meta='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = pd.json_normalize(data['list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'list' not found. If specifying a record_path, all elements of data should have the path.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fashaikh\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:396\u001b[0m, in \u001b[0;36m_json_normalize.<locals>._pull_field\u001b[1;34m(js, spec, extract_record)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 396\u001b[0m         result \u001b[39m=\u001b[39m result[spec]\n\u001b[0;32m    397\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fashaikh\\Desktop\\AQI\\historical_weather.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fashaikh/Desktop/AQI/historical_weather.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dw \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mjson_normalize(result, \u001b[39m'\u001b[39;49m\u001b[39mlist\u001b[39;49m\u001b[39m'\u001b[39;49m, meta\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m], errors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mignore\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fashaikh/Desktop/AQI/historical_weather.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dn \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mjson_normalize(result[\u001b[39m'\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m'\u001b[39m], record_path\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mweather\u001b[39m\u001b[39m'\u001b[39m], record_prefix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweather.\u001b[39m\u001b[39m'\u001b[39m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/fashaikh/Desktop/AQI/historical_weather.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dw \u001b[39m=\u001b[39m dw\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mweather\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fashaikh\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:515\u001b[0m, in \u001b[0;36m_json_normalize\u001b[1;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[0;32m    512\u001b[0m                 meta_vals[key]\u001b[39m.\u001b[39mappend(meta_val)\n\u001b[0;32m    513\u001b[0m             records\u001b[39m.\u001b[39mextend(recs)\n\u001b[1;32m--> 515\u001b[0m _recursive_extract(data, record_path, {}, level\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    517\u001b[0m result \u001b[39m=\u001b[39m DataFrame(records)\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m record_prefix \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[39m# Incompatible types in assignment (expression has type \"Optional[DataFrame]\",\u001b[39;00m\n\u001b[0;32m    521\u001b[0m     \u001b[39m# variable has type \"DataFrame\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fashaikh\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:497\u001b[0m, in \u001b[0;36m_json_normalize.<locals>._recursive_extract\u001b[1;34m(data, path, seen_meta, level)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m data:\n\u001b[1;32m--> 497\u001b[0m         recs \u001b[39m=\u001b[39m _pull_records(obj, path[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    498\u001b[0m         recs \u001b[39m=\u001b[39m [\n\u001b[0;32m    499\u001b[0m             nested_to_record(r, sep\u001b[39m=\u001b[39msep, max_level\u001b[39m=\u001b[39mmax_level)\n\u001b[0;32m    500\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(r, \u001b[39mdict\u001b[39m)\n\u001b[0;32m    501\u001b[0m             \u001b[39melse\u001b[39;00m r\n\u001b[0;32m    502\u001b[0m             \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m recs\n\u001b[0;32m    503\u001b[0m         ]\n\u001b[0;32m    505\u001b[0m         \u001b[39m# For repeating the metadata later\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fashaikh\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:419\u001b[0m, in \u001b[0;36m_json_normalize.<locals>._pull_records\u001b[1;34m(js, spec)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pull_records\u001b[39m(js: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any], spec: \u001b[39mlist\u001b[39m \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[0;32m    414\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[39m    Internal function to pull field for records, and similar to\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[39m    _pull_field, but require to return list. And will raise error\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    if has non iterable value.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     result \u001b[39m=\u001b[39m _pull_field(js, spec, extract_record\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    421\u001b[0m     \u001b[39m# GH 31507 GH 30145, GH 26284 if result is not list, raise TypeError if not\u001b[39;00m\n\u001b[0;32m    422\u001b[0m     \u001b[39m# null, otherwise return an empty list\u001b[39;00m\n\u001b[0;32m    423\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\fashaikh\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py:399\u001b[0m, in \u001b[0;36m_json_normalize.<locals>._pull_field\u001b[1;34m(js, spec, extract_record)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    398\u001b[0m     \u001b[39mif\u001b[39;00m extract_record:\n\u001b[1;32m--> 399\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m    400\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m not found. If specifying a record_path, all elements of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata should have the path.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[39melif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'list' not found. If specifying a record_path, all elements of data should have the path.\""
     ]
    }
   ],
   "source": [
    "dw = pd.json_normalize(result, 'list', meta=['url'], errors='ignore')\n",
    "dn = pd.json_normalize(result['list'], record_path=['weather'], record_prefix='weather.' )\n",
    "dw = dw.drop('weather', axis=1)\n",
    "dw['dt'] = dw['dt'].apply(lambda t: hour_rounder(datetime.utcfromtimestamp(t)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "df_update = pd.concat([dw,dn], axis=1)\n",
    "df_update['lat'] = df_update['url'].apply(lambda t: t.split('lat=')[1].split('&lon')[0])\n",
    "df_update['lon'] = df_update['url'].apply(lambda t: t.split('lon=')[1].split('&type')[0])\n",
    "df_update = df_update.drop('url', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da24c822f958bb83a104dff98dc7b915134eb9cfe2a236abb560fb6bddae8834"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
